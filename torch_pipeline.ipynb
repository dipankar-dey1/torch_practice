{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ab49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cca7b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c67994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b6b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ec43b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f340756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8003530",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a045d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40213391, -0.38819252, -0.45526166, ..., -1.18993189,\n",
       "        -1.17680271, -1.31066142],\n",
       "       [ 3.20197173,  1.29914673,  3.32851967, ...,  2.6031412 ,\n",
       "        -0.87944617,  1.14717878],\n",
       "       [-0.09650575, -0.82634138, -0.14635596, ..., -1.23534342,\n",
       "        -1.65570325, -0.88047088],\n",
       "       ...,\n",
       "       [-1.26077604, -0.05025855, -1.25156119, ..., -1.0420417 ,\n",
       "         0.4367478 , -0.22340279],\n",
       "       [ 0.14280686, -0.84964717,  0.0338042 , ..., -0.85676269,\n",
       "        -0.60556514, -1.49150585],\n",
       "       [ 0.98760922, -0.00364697,  0.97097143, ...,  1.19841144,\n",
       "         0.01731857, -0.3012207 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15118168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429    B\n",
       "82     M\n",
       "442    B\n",
       "20     B\n",
       "523    B\n",
       "      ..\n",
       "419    B\n",
       "306    B\n",
       "424    B\n",
       "311    B\n",
       "201    M\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a37e4d",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa2ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a845ad58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856ba7b",
   "metadata": {},
   "source": [
    "### Numpy arrays to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444ee615",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5543af65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e4e4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425794f",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "231ca066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN():\n",
    "    def __init__(self,X):\n",
    "        self.weights = torch.rand(X.shape[1],1, dtype= torch.float32, requires_grad=True)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float32, requires_grad=True)\n",
    "    def forward(self, X):\n",
    "        z= torch.matmul(X, self.weights) + self.bias\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "    def loss_function(self, y_pred, y):\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = -(y_train_tensor * torch.log(y_pred) + (1 - y_train_tensor) * torch.log(1 - y_pred)).mean()\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9e15843",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important parameters\n",
    "learning_rate= 0.1\n",
    "epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "496ce05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 3.4736900329589844\n",
      "Epoch: 2, loss: 3.3375494480133057\n",
      "Epoch: 3, loss: 3.197540044784546\n",
      "Epoch: 4, loss: 3.0573010444641113\n",
      "Epoch: 5, loss: 2.914172410964966\n",
      "Epoch: 6, loss: 2.768662929534912\n",
      "Epoch: 7, loss: 2.6198511123657227\n",
      "Epoch: 8, loss: 2.4618523120880127\n",
      "Epoch: 9, loss: 2.3020431995391846\n",
      "Epoch: 10, loss: 2.143686532974243\n",
      "Epoch: 11, loss: 1.9836167097091675\n",
      "Epoch: 12, loss: 1.8270740509033203\n",
      "Epoch: 13, loss: 1.6798564195632935\n",
      "Epoch: 14, loss: 1.5429797172546387\n",
      "Epoch: 15, loss: 1.4134129285812378\n",
      "Epoch: 16, loss: 1.2975941896438599\n",
      "Epoch: 17, loss: 1.1925783157348633\n",
      "Epoch: 18, loss: 1.1031454801559448\n",
      "Epoch: 19, loss: 1.0293382406234741\n",
      "Epoch: 20, loss: 0.9701436758041382\n",
      "Epoch: 21, loss: 0.9236375689506531\n",
      "Epoch: 22, loss: 0.8874213695526123\n",
      "Epoch: 23, loss: 0.8591229319572449\n",
      "Epoch: 24, loss: 0.8366994261741638\n",
      "Epoch: 25, loss: 0.8185704350471497\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "model = MySimpleNN(X_train_tensor)\n",
    "model.weights\n",
    "for epoch in range(epochs):\n",
    "\n",
    "     #Forward pass\n",
    "     y_pred = model.forward(X_train_tensor)\n",
    "     #print(y_pred)\n",
    "\n",
    "\n",
    "    #loss calculate\n",
    "     loss = model.loss_function(y_pred, y_train_tensor)\n",
    "     \n",
    "     #backword pass\n",
    "     loss.backward()\n",
    "\n",
    "\n",
    "     #parameters update, \n",
    "     with torch.no_grad(): # For not tracking gradient here\n",
    "        model.weights-=learning_rate * model.weights.grad\n",
    "        model.bias-= learning_rate * model.bias.grad\n",
    "        \n",
    "    #zero gradient  # To not accumalate gradient\n",
    "     model.weights.grad.zero_()\n",
    "     model.bias.grad.zero_()\n",
    "    #Print loss\n",
    "     print(f\"Epoch: {epoch+1}, loss: {loss.item()}\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b7f61a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1968],\n",
       "        [-0.0037],\n",
       "        [ 0.0338],\n",
       "        [ 0.1468],\n",
       "        [ 0.0316],\n",
       "        [ 0.1392],\n",
       "        [ 0.1994],\n",
       "        [-0.1735],\n",
       "        [ 0.3281],\n",
       "        [ 0.1609],\n",
       "        [-0.2869],\n",
       "        [ 0.3096],\n",
       "        [-0.1175],\n",
       "        [ 0.2129],\n",
       "        [ 0.5626],\n",
       "        [-0.2273],\n",
       "        [ 0.0207],\n",
       "        [-0.0133],\n",
       "        [-0.0133],\n",
       "        [ 0.3194],\n",
       "        [-0.3724],\n",
       "        [ 0.0298],\n",
       "        [ 0.5104],\n",
       "        [-0.0740],\n",
       "        [ 0.1633],\n",
       "        [-0.4393],\n",
       "        [-0.0784],\n",
       "        [-0.2264],\n",
       "        [ 0.4472],\n",
       "        [-0.2558]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7392ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1463], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f56fc84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5184672474861145\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred > 0.5).float()\n",
    "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "    print(f'Accuracy: {accuracy.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c812615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN():\n",
    "\n",
    "  def __init__(self, X):\n",
    "\n",
    "    self.weights = torch.rand(X.shape[1], 1, dtype=torch.float32, requires_grad=True)\n",
    "    self.bias = torch.zeros(1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "  def forward(self, X):\n",
    "    z = torch.matmul(X, self.weights) + self.bias\n",
    "    y_pred = torch.sigmoid(z)\n",
    "    return y_pred\n",
    "\n",
    "  def loss_function(self, y_pred, y):\n",
    "    # Clamp predictions to avoid log(0)\n",
    "    epsilon = 1e-7\n",
    "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = -(y_train_tensor * torch.log(y_pred) + (1 - y_train_tensor) * torch.log(1 - y_pred)).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd020a6",
   "metadata": {},
   "source": [
    "### Important Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2e3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f0684",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8691b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 4.012610912322998\n",
      "Epoch: 2, Loss: 3.898456335067749\n",
      "Epoch: 3, Loss: 3.778489828109741\n",
      "Epoch: 4, Loss: 3.6573500633239746\n",
      "Epoch: 5, Loss: 3.5286149978637695\n",
      "Epoch: 6, Loss: 3.3946518898010254\n",
      "Epoch: 7, Loss: 3.2562828063964844\n",
      "Epoch: 8, Loss: 3.1127312183380127\n",
      "Epoch: 9, Loss: 2.962118148803711\n",
      "Epoch: 10, Loss: 2.809065818786621\n",
      "Epoch: 11, Loss: 2.6479341983795166\n",
      "Epoch: 12, Loss: 2.4864094257354736\n",
      "Epoch: 13, Loss: 2.319244623184204\n",
      "Epoch: 14, Loss: 2.153815984725952\n",
      "Epoch: 15, Loss: 1.9901200532913208\n",
      "Epoch: 16, Loss: 1.8302905559539795\n",
      "Epoch: 17, Loss: 1.679955005645752\n",
      "Epoch: 18, Loss: 1.5370005369186401\n",
      "Epoch: 19, Loss: 1.4050240516662598\n",
      "Epoch: 20, Loss: 1.283604383468628\n",
      "Epoch: 21, Loss: 1.1779180765151978\n",
      "Epoch: 22, Loss: 1.0883663892745972\n",
      "Epoch: 23, Loss: 1.0149729251861572\n",
      "Epoch: 24, Loss: 0.9570441246032715\n",
      "Epoch: 25, Loss: 0.9129980802536011\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = MySimpleNN(X_train_tensor)\n",
    "\n",
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  # forward pass\n",
    "  y_pred = model.forward(X_train_tensor)\n",
    "\n",
    "  # loss calculate\n",
    "  loss = model.loss_function(y_pred, y_train_tensor)\n",
    "\n",
    "  # backward pass\n",
    "  loss.backward()\n",
    "\n",
    "  # parameters update\n",
    "  with torch.no_grad():  #To not track gradient here\n",
    "    model.weights -= learning_rate * model.weights.grad\n",
    "    model.bias -= learning_rate * model.bias.grad\n",
    "\n",
    "  # zero gradients , to  not accumate gradient\n",
    "  model.weights.grad.zero_()\n",
    "  model.bias.grad.zero_()\n",
    "\n",
    "  # print loss in each epoch\n",
    "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "301b974e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1086], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cadb8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a92fbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6084949374198914\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "with torch.no_grad():\n",
    "  y_pred = model.forward(X_test_tensor)\n",
    "  y_pred = (y_pred > 0.9).float()\n",
    "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "  print(f'Accuracy: {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0eaaf3",
   "metadata": {},
   "source": [
    "üöÄ 1. Improvements Planned (Notebook Cell with Print Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18ee60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pipeline Improvements Implemented:\n",
      "1Ô∏è‚É£ Model defined using nn.Linear instead of manual weights/bias.\n",
      "2Ô∏è‚É£ Activation functions from nn (Sigmoid, ReLU).\n",
      "3Ô∏è‚É£ Built-in loss function (nn.BCELoss).\n",
      "4Ô∏è‚É£ Parameter updates using torch.optim.SGD.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Pipeline Improvements Implemented:\")\n",
    "print(\"1Ô∏è‚É£ Model defined using nn.Linear instead of manual weights/bias.\")\n",
    "print(\"2Ô∏è‚É£ Activation functions from nn (Sigmoid, ReLU).\")\n",
    "print(\"3Ô∏è‚É£ Built-in loss function (nn.BCELoss).\")\n",
    "print(\"4Ô∏è‚É£ Parameter updates using torch.optim.SGD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969daa57",
   "metadata": {},
   "source": [
    "### Simple  one  node network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3540853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#practice one neural  layer\n",
    "# 5 features and 1 output , binary classification\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid= nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, features):\n",
    "        out = self.linear(features)\n",
    "        out= self.sigmoid(out)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dde9029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5988],\n",
       "        [0.6017],\n",
       "        [0.5174],\n",
       "        [0.5045],\n",
       "        [0.5135],\n",
       "        [0.4542],\n",
       "        [0.4963],\n",
       "        [0.5032],\n",
       "        [0.4679],\n",
       "        [0.5583]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset\n",
    "features = torch.rand(10,5)\n",
    "\n",
    "# create model\n",
    "model = Model(features.shape[1])\n",
    "\n",
    "# call model for forward pass\n",
    "# model.forward(features)\n",
    "model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55c8497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=5, out_features=1, bias=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f07b4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2896, -0.1395,  0.2355,  0.3179, -0.0629]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57d1e51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0970], requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50d8bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    [10, 1]                   --\n",
       "‚îú‚îÄLinear: 1-1                            [10, 1]                   6\n",
       "‚îú‚îÄSigmoid: 1-2                           [10, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 6\n",
       "Trainable params: 6\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size= (10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e289f7",
   "metadata": {},
   "source": [
    "#### Simple 3 node in 1st layer and one  node  in second  layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc452874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practice with 3 neuron in first layer and one neuron in second layer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_features, 3) #Linear 1 is the name of the  first layer, with 5 input and 3 ouput\n",
    "        self.relu = nn.ReLU()    #Applying ReLU on it \n",
    "        self.linear2 = nn.Linear(3,1)  # Linear 2 is the name of the second layer with 3 input and one output \n",
    "        self.sigmoid = nn.Sigmoid()    #Applying Sigmoid on it\n",
    "    \n",
    "    def forward(self, features):\n",
    "\n",
    "        out = self.linear1(features)\n",
    "        out = self.relu(out)\n",
    "        out= self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "967f3be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2929],\n",
       "        [0.3292],\n",
       "        [0.2956],\n",
       "        [0.3517],\n",
       "        [0.3208],\n",
       "        [0.3538],\n",
       "        [0.3335],\n",
       "        [0.3030],\n",
       "        [0.3124],\n",
       "        [0.3027]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset\n",
    "features = torch.rand(10,5)\n",
    "\n",
    "# create model\n",
    "model = Model(features.shape[1])\n",
    "\n",
    "# call model for forward pass\n",
    "# model.forward(features)\n",
    "model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a01b8344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1598, -0.0681,  0.3176,  0.4295,  0.1287],\n",
       "        [ 0.2043, -0.2830, -0.2448,  0.3690, -0.2016],\n",
       "        [ 0.2320,  0.0190,  0.3477,  0.3712,  0.2646]], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30eb68ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2490,  0.4317, -0.4082], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5432568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    [10, 1]                   --\n",
       "‚îú‚îÄLinear: 1-1                            [10, 3]                   18\n",
       "‚îú‚îÄReLU: 1-2                              [10, 3]                   --\n",
       "‚îú‚îÄLinear: 1-3                            [10, 1]                   4\n",
       "‚îú‚îÄSigmoid: 1-4                           [10, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 22\n",
       "Trainable params: 22\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size= (10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e9c3c",
   "metadata": {},
   "source": [
    "### Same network Sequential container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b582fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        out = self.network(features)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7480b8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4810],\n",
       "        [0.5023],\n",
       "        [0.4831],\n",
       "        [0.4794],\n",
       "        [0.4980],\n",
       "        [0.4850],\n",
       "        [0.4901],\n",
       "        [0.4970],\n",
       "        [0.4989],\n",
       "        [0.4945]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset\n",
    "features = torch.rand(10,5)\n",
    "\n",
    "# create model\n",
    "model = Model(features.shape[1])\n",
    "\n",
    "# call model for forward pass\n",
    "# model.forward(features)\n",
    "model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e2dad",
   "metadata": {},
   "source": [
    "##### How to find the weights of the layer like we did before ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd8eaddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    [10, 1]                   --\n",
       "‚îú‚îÄSequential: 1-1                        [10, 1]                   --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-1                       [10, 3]                   18\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-2                         [10, 3]                   --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-3                       [10, 1]                   4\n",
       "‚îÇ    ‚îî‚îÄSigmoid: 2-4                      [10, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 22\n",
       "Trainable params: 22\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac48eebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5d36cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        out = self.network(features)\n",
    "        return out \n",
    "    \n",
    "    def loss_function(self, y_pred, y):\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Binary cross entropy manually\n",
    "        loss = -(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5052963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.1\n",
    "epochs= 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e2e222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, loss: 0.7314310073852539\n",
      "Epoch : 2, loss: 0.7263287901878357\n",
      "Epoch : 3, loss: 0.7216006517410278\n",
      "Epoch : 4, loss: 0.717167317867279\n",
      "Epoch : 5, loss: 0.7130776643753052\n",
      "Epoch : 6, loss: 0.7093329429626465\n",
      "Epoch : 7, loss: 0.7058620452880859\n",
      "Epoch : 8, loss: 0.7026875019073486\n",
      "Epoch : 9, loss: 0.6997913718223572\n",
      "Epoch : 10, loss: 0.6971470713615417\n",
      "Epoch : 11, loss: 0.694744884967804\n",
      "Epoch : 12, loss: 0.6925541162490845\n",
      "Epoch : 13, loss: 0.6905393600463867\n",
      "Epoch : 14, loss: 0.6887276768684387\n",
      "Epoch : 15, loss: 0.687079906463623\n",
      "Epoch : 16, loss: 0.6855831146240234\n",
      "Epoch : 17, loss: 0.6842206716537476\n",
      "Epoch : 18, loss: 0.682981014251709\n",
      "Epoch : 19, loss: 0.6818594336509705\n",
      "Epoch : 20, loss: 0.6808431148529053\n",
      "Epoch : 21, loss: 0.6799180507659912\n",
      "Epoch : 22, loss: 0.6790823936462402\n",
      "Epoch : 23, loss: 0.6783280372619629\n",
      "Epoch : 24, loss: 0.6776466965675354\n",
      "Epoch : 25, loss: 0.6770285367965698\n"
     ]
    }
   ],
   "source": [
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward\n",
    "    y_pred = model(X_train_tensor)\n",
    "    #Losss\n",
    "    loss= model.loss_function(y_pred, y_train_tensor)\n",
    "    #Calculate gradient/ Backward pass\n",
    "    loss.backward()\n",
    "    #Update weight\n",
    "    with torch.no_grad(): #So that it does not track gradient while updating weight\n",
    "        for param in model.parameters():        # FIXED\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "    #Gradient not to accumalate\n",
    "     # Reset gradients\n",
    "    model.zero_grad()  \n",
    "    print(f\"Epoch : {epoch+1}, loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531edc7",
   "metadata": {},
   "source": [
    "### Using built in loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e0cf780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        out = self.network(features)\n",
    "        return out \n",
    "    \n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "855e85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, loss: 0.6865769624710083\n",
      "Epoch : 2, loss: 0.674626350402832\n",
      "Epoch : 3, loss: 0.6640343070030212\n",
      "Epoch : 4, loss: 0.6531378626823425\n",
      "Epoch : 5, loss: 0.6419836282730103\n",
      "Epoch : 6, loss: 0.6297799944877625\n",
      "Epoch : 7, loss: 0.6164185404777527\n",
      "Epoch : 8, loss: 0.6016473174095154\n",
      "Epoch : 9, loss: 0.5856695771217346\n",
      "Epoch : 10, loss: 0.5687410831451416\n",
      "Epoch : 11, loss: 0.5513021349906921\n",
      "Epoch : 12, loss: 0.5331749320030212\n",
      "Epoch : 13, loss: 0.5150456428527832\n",
      "Epoch : 14, loss: 0.49712735414505005\n",
      "Epoch : 15, loss: 0.4797016382217407\n",
      "Epoch : 16, loss: 0.4628044664859772\n",
      "Epoch : 17, loss: 0.4464823603630066\n",
      "Epoch : 18, loss: 0.43085411190986633\n",
      "Epoch : 19, loss: 0.41582393646240234\n",
      "Epoch : 20, loss: 0.40143895149230957\n",
      "Epoch : 21, loss: 0.3876883387565613\n",
      "Epoch : 22, loss: 0.3744199573993683\n",
      "Epoch : 23, loss: 0.36177858710289\n",
      "Epoch : 24, loss: 0.34971508383750916\n",
      "Epoch : 25, loss: 0.3382209837436676\n"
     ]
    }
   ],
   "source": [
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "for epoch in range(epochs):\n",
    "    # Forward\n",
    "    y_pred= model(X_train_tensor)\n",
    "    #Loss\n",
    "    loss = criterion(y_pred, y_train_tensor.view(-1,1))\n",
    "\n",
    "    #Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #parameterss update\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param-=learning_rate*param.grad\n",
    "   #Gradient not to accumalate\n",
    "   # Reset gradients\n",
    "    model.zero_grad()  \n",
    "    print(f\"Epoch : {epoch+1}, loss: {loss.item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bde76025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of MySimpleNN(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=3, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=3, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93af1b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0076, -0.0615,  0.2904, -0.0164, -0.0414,  0.1766,  0.0421, -0.0319,\n",
      "         -0.0023, -0.1339,  0.0679, -0.0460,  0.1606,  0.1207, -0.1481,  0.1810,\n",
      "         -0.1164,  0.1347,  0.0971, -0.1842, -0.0337,  0.2493,  0.2297, -0.0319,\n",
      "          0.1155,  0.2716,  0.1964,  0.1150,  0.0271,  0.2436],\n",
      "        [-0.1144, -0.0306, -0.1699,  0.0457, -0.1047, -0.0928, -0.1242, -0.0845,\n",
      "         -0.1649, -0.1445, -0.2141,  0.0947, -0.1425, -0.2213, -0.1451, -0.1707,\n",
      "         -0.1861, -0.1212, -0.1022, -0.2056, -0.2244,  0.0426, -0.1564, -0.2629,\n",
      "         -0.1092,  0.0028,  0.0344,  0.0326, -0.0769, -0.0557],\n",
      "        [ 0.2400,  0.0191,  0.1018, -0.0475,  0.0629,  0.0875,  0.1501,  0.2464,\n",
      "          0.1296, -0.1849,  0.1248, -0.0286,  0.0960, -0.0579,  0.1232,  0.1660,\n",
      "         -0.0684,  0.1110,  0.0259, -0.1410, -0.0232,  0.1353,  0.1360,  0.2298,\n",
      "         -0.0344,  0.2365, -0.0416, -0.0583, -0.0900, -0.0559]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0715,  0.0393, -0.1053], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#1. View first layer weights and bias\n",
    "print(model.network[0].weight)\n",
    "print(model.network[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fc64d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5438596606254578\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "with torch.no_grad():\n",
    "  y_pred = model.forward(X_test_tensor)\n",
    "  y_pred = (y_pred > 0.5).float()\n",
    "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "  print(f'Accuracy: {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9918933",
   "metadata": {},
   "source": [
    "#### Use built in optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b7deb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definne the model\n",
    "class MySimpleNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network =  nn.Sequential(\n",
    "            nn.Linear(num_features,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, features):\n",
    "        out = self.network(features)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cc9d410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , loss: 0.6758602857589722\n",
      "Epoch: 2 , loss: 0.6567738056182861\n",
      "Epoch: 3 , loss: 0.6385887265205383\n",
      "Epoch: 4 , loss: 0.6206203103065491\n",
      "Epoch: 5 , loss: 0.6034156680107117\n",
      "Epoch: 6 , loss: 0.5865950584411621\n",
      "Epoch: 7 , loss: 0.5700075030326843\n",
      "Epoch: 8 , loss: 0.5537471175193787\n",
      "Epoch: 9 , loss: 0.5376129746437073\n",
      "Epoch: 10 , loss: 0.5212992429733276\n",
      "Epoch: 11 , loss: 0.505332887172699\n",
      "Epoch: 12 , loss: 0.48961421847343445\n",
      "Epoch: 13 , loss: 0.47393715381622314\n",
      "Epoch: 14 , loss: 0.4583646357059479\n",
      "Epoch: 15 , loss: 0.44319745898246765\n",
      "Epoch: 16 , loss: 0.4284417927265167\n",
      "Epoch: 17 , loss: 0.41403087973594666\n",
      "Epoch: 18 , loss: 0.4000888764858246\n",
      "Epoch: 19 , loss: 0.38660529255867004\n",
      "Epoch: 20 , loss: 0.37362247705459595\n",
      "Epoch: 21 , loss: 0.3612004518508911\n",
      "Epoch: 22 , loss: 0.3491678535938263\n",
      "Epoch: 23 , loss: 0.33762720227241516\n",
      "Epoch: 24 , loss: 0.3266150951385498\n",
      "Epoch: 25 , loss: 0.31602951884269714\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #Forward\n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    #Loss\n",
    "    loss = criterion(y_pred, y_train_tensor.view(-1,1))\n",
    "\n",
    "    #backkward\n",
    "    loss.backward()\n",
    "\n",
    "    #paramter update\n",
    "    optimizer.step()\n",
    "\n",
    "    #zero grad\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"Epoch: {epoch+1} , loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246e814",
   "metadata": {},
   "source": [
    "## Using mini batch SGD, untill now GD was going that is full dataset was given as input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d0e693",
   "metadata": {},
   "source": [
    "##### Here we have the X_train_tensor and y_train_tensor ready in tabular , and sometime these are not availale as easy as it is there , and also if we want to apply something on all data than we don't have anything and also if we want to shuffle and do paraller processing , so for all of these we have Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe55810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , loss: 0.5795527696609497\n",
      "Epoch: 2 , loss: 0.37572285532951355\n",
      "Epoch: 3 , loss: 0.2591848075389862\n",
      "Epoch: 4 , loss: 0.17249147593975067\n",
      "Epoch: 5 , loss: 0.11731104552745819\n",
      "Epoch: 6 , loss: 0.08386725932359695\n",
      "Epoch: 7 , loss: 0.06280896067619324\n",
      "Epoch: 8 , loss: 0.04918437823653221\n",
      "Epoch: 9 , loss: 0.03985678032040596\n",
      "Epoch: 10 , loss: 0.033180736005306244\n",
      "Epoch: 11 , loss: 0.028220126405358315\n",
      "Epoch: 12 , loss: 0.02445669285953045\n",
      "Epoch: 13 , loss: 0.021395178511738777\n",
      "Epoch: 14 , loss: 0.018822507932782173\n",
      "Epoch: 15 , loss: 0.016777072101831436\n",
      "Epoch: 16 , loss: 0.01504064816981554\n",
      "Epoch: 17 , loss: 0.01361093856394291\n",
      "Epoch: 18 , loss: 0.012517332099378109\n",
      "Epoch: 19 , loss: 0.011434225365519524\n",
      "Epoch: 20 , loss: 0.010635294951498508\n",
      "Epoch: 21 , loss: 0.009908589534461498\n",
      "Epoch: 22 , loss: 0.009114272892475128\n",
      "Epoch: 23 , loss: 0.00847525242716074\n",
      "Epoch: 24 , loss: 0.007937160320580006\n",
      "Epoch: 25 , loss: 0.0074122450314462185\n"
     ]
    }
   ],
   "source": [
    "batch_size =32\n",
    "epochs=25\n",
    "learning_rate= 0.1\n",
    "criterion = nn.BCELoss()\n",
    "n_samples = len(X_train_tensor)\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for start_idx in range(0, n_samples, batch_size):\n",
    "        end_idx = start_idx+ batch_size\n",
    "        X_batch = X_train_tensor[start_idx:end_idx]\n",
    "        y_batch = y_train_tensor[start_idx:end_idx]\n",
    "\n",
    "        #Forward\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        #Loss\n",
    "        loss = criterion(y_pred, y_batch.view(-1,1))\n",
    "\n",
    "        #backkward\n",
    "        loss.backward()\n",
    "\n",
    "        #paramter update\n",
    "        optimizer.step()\n",
    "\n",
    "        #zero grad\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"Epoch: {epoch+1} , loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8734c",
   "metadata": {},
   "source": [
    "### Batch processing using Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ed73827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f32778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=10,\n",
    "    n_features=2,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b09f1dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06833894, -0.97007347],\n",
       "       [-1.14021544, -0.83879234],\n",
       "       [-2.8953973 ,  1.97686236],\n",
       "       [-0.72063436, -0.96059253],\n",
       "       [-1.96287438, -0.99225135],\n",
       "       [-0.9382051 , -0.54304815],\n",
       "       [ 1.72725924, -1.18582677],\n",
       "       [ 1.77736657,  1.51157598],\n",
       "       [ 1.89969252,  0.83444483],\n",
       "       [-0.58723065, -1.97171753]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a82db4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 2), array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8510ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype = torch.float32)\n",
    "y= torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6be5292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45d71c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using Dataset, this  is used to perform any type of preprocessing in overall dataset\n",
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features=features\n",
    "        self.labels= labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98161d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= Custom_Dataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77ae4d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " tensor([[ 1.0683, -0.9701],\n",
       "         [-1.1402, -0.8388],\n",
       "         [-2.8954,  1.9769],\n",
       "         [-0.7206, -0.9606],\n",
       "         [-1.9629, -0.9923],\n",
       "         [-0.9382, -0.5430],\n",
       "         [ 1.7273, -1.1858],\n",
       "         [ 1.7774,  1.5116],\n",
       "         [ 1.8997,  0.8344],\n",
       "         [-0.5872, -1.9717]]),\n",
       " tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), dataset.features, dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6c0974cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8997,  0.8344],\n",
      "        [-2.8954,  1.9769]])\n",
      "tensor([1, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.9629, -0.9923],\n",
      "        [ 1.7774,  1.5116]])\n",
      "tensor([0, 1])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.1402, -0.8388],\n",
      "        [-0.5872, -1.9717]])\n",
      "tensor([0, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[ 1.7273, -1.1858],\n",
      "        [-0.7206, -0.9606]])\n",
      "tensor([1, 0])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.9382, -0.5430],\n",
      "        [ 1.0683, -0.9701]])\n",
      "tensor([1, 1])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle = True) # So for 10 points if batch size is  2 , than there are 5 batches\n",
    "for batch_features, batch_labels in dataloader:\n",
    "    print(batch_features)\n",
    "    print(batch_labels)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b4038",
   "metadata": {},
   "source": [
    "### Applying Dataset and DataLoader for processing in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "42f7f104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv') \n",
    "df.head()\n",
    "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)\n",
    "df.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train\n",
    "y_train\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test) \n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()\n",
    "X_train_tensor.shape\n",
    "y_train_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "feff8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features=features\n",
    "        self.labels= labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "baca6c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.7508,  0.5342,  1.6759,  1.7584, -0.3696,  0.1333,  0.1020,  0.7132,\n",
       "         -0.7204, -1.0432,  0.5772, -0.5307,  0.6085,  0.6421, -0.2423, -0.3545,\n",
       "         -0.2834,  0.4857, -0.7181, -0.7398,  1.6238,  0.0899,  1.5594,  1.5231,\n",
       "          0.0049, -0.1201, -0.0125,  0.9277, -0.4852, -0.9257]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset= Custom_Dataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset= Custom_Dataset(X_test_tensor, y_test_tensor)\n",
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d0bdf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =DataLoader(train_dataset, batch_size=32, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee274027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definne the model\n",
    "class MySimpleNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network =  nn.Sequential(\n",
    "            nn.Linear(num_features,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, features):\n",
    "        out = self.network(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d4924d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , loss: 0.2043236643075943\n",
      "Epoch: 2 , loss: 2.3375144004821777\n",
      "Epoch: 3 , loss: 0.0022446538787335157\n",
      "Epoch: 4 , loss: 3.624991403130066e-20\n",
      "Epoch: 5 , loss: 5.365813349200721e-10\n",
      "Epoch: 6 , loss: 9.811769996304065e-05\n",
      "Epoch: 7 , loss: 0.9066342115402222\n",
      "Epoch: 8 , loss: 1.720682405448315e-07\n",
      "Epoch: 9 , loss: 1.2982219457626343\n",
      "Epoch: 10 , loss: 1.606576370249968e-05\n",
      "Epoch: 11 , loss: 1.8063074350357056\n",
      "Epoch: 12 , loss: 3.8208509067771956e-05\n",
      "Epoch: 13 , loss: 14.285761833190918\n",
      "Epoch: 14 , loss: 3.9944723539520055e-05\n",
      "Epoch: 15 , loss: 8.191468805307522e-05\n",
      "Epoch: 16 , loss: 0.0004264604358468205\n",
      "Epoch: 17 , loss: 0.0006997570162639022\n",
      "Epoch: 18 , loss: 0.005690908990800381\n",
      "Epoch: 19 , loss: 0.01282199565321207\n",
      "Epoch: 20 , loss: 0.05178327113389969\n",
      "Epoch: 21 , loss: 0.0\n",
      "Epoch: 22 , loss: 0.1045197919011116\n",
      "Epoch: 23 , loss: 0.08015710860490799\n",
      "Epoch: 24 , loss: 0.01810978725552559\n",
      "Epoch: 25 , loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "learning_rate= 0.1\n",
    "epochs=25\n",
    "model =MySimpleNN(X_train_tensor.shape[1])\n",
    "optimizer= torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "criterion= nn.BCELoss() \n",
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "        #Forward\n",
    "        y_pred = model(batch_features)\n",
    "\n",
    "        #Loss\n",
    "        loss= criterion(y_pred, batch_labels.view(-1,1))\n",
    "\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # parameters update\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1} , loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d8a8a",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "979a03ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9410\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using test_loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fb78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
